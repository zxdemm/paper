# 想法

## 过拟合补丁：

阳性的测试用例指的是在该软件下合法的输入的测试用例。比如加法软件，输入的值为实数。那么实数就是阳性的测试用例。虚数就是阴性的测试用例

1. 给出足够的错误的测试用例，使得bug暴露地足够多(Defects4j给定了bug)

2. 用手写的补丁与APR补丁进行比较

3. 得到补丁后动态生成测试用例，再对补丁进行检测（这个想法已经被人提出来了）:

   想法来源：《Identifying Patch Correctness in Test-Based Program Repair》

4. 基于测试输入的启发式检测。根据测试输入的执行路径来对新生成的测试输入和补丁进行分类。不再对测试的输出进行讨论

   想法来源：《Identifying Patch Correctness in Test-Based Program Repair》

   ==其中测试执行的公式可以按照bug语句的可疑度来添加权值==
   
5. **根据给定的测试用例来推测测试的oracle来对补丁进行启发式分类**

6. 缓解过拟合程度：用新的测试用例不断增强约束，然后对约束求解来求出更好的补丁

7. 有一种方法：建立一种新的bug程序集，这个集合用JML来描述每一个模块，用OpenJML等工具来检测生成的补丁是否正确。文章在《Exploring True Test Overfitting in Dynamic Automated Program Repair using Formal Methods》，但是作者没有给出他的项目集。

## 遗传编程设计中的适应度计算

1. 充分利用测试用例的输入与输出，而不是单纯地看测试用例是否通过
2. 可以用人工智能来计算损失函数
3. 将程序变体的编译出错、超时等情况也考虑到适应度里，并占有一定的权值
4. 编译出错和超时的程序变体，对出错的问题语句进行变异，变异两次，一旦变异两次之后不能通过时，则抛弃这个程序变体

## 成分语句

1. 编写一个数据库，使得可以用来充当成分语句，借此来修复小型的程序

# 测试用例

1. 去除冗余测试用例：利用测试用例的执行路径来去除相同类型的测试用例。比如用最长公共子序列、Levenshtein距离、汉明距离来比较两条执行路径
2. 在进行过拟合验证的时候，一般需要产生新的测试用例。那么如何确定这个测试用例是通过还是失败需要有新算法来完成。最好不是用人工来分类

## 测试用例生成工具

1. Randloop:随机测试生成
2. KATCH

## 已给出的补丁集（是否正确）

1. Identifying Patch Correctness in Test-Based Program Repair这篇作者给出了
2.  syntax and semantic-guided repair synthesis via programming by example
3. Automatic repair of real bugs in java: a large-scale experiment on the defects4j dataset

## 一些可靠的程序集

1. IntroClass: 一些学生提交的c语言入门程序，以及还有两个高质量的测试集，分别为基于黑盒与白盒的测试集
2. Codeflaws benchmarks：一个竞赛的程序集也有测试用例，《a programming competition
   benchmark for evaluating automated program repair tools》



### 基于模板的修复

1. facebook中给出了新的修复工具，从历史的bug修复中，提取修复。然后给出一个具有层次的模板。叶节点是最具体的编辑，根节点是最抽象的编辑

# 论文想法

1. 利用Exploring_True_Test_Overfitting_in_Dynamic_Automated_Program_Repair_using_Formal_Methods这篇论文给出的数据集来生成补丁，然后对生成的补丁进行评估。评估的是补丁的质量，从时间、空间复杂度入手。

2. 再对上述想法进行深入思考：能不能写一些数据集，专门是一些时间复杂度或空间复杂度较高的程序。然后通过修复程序进行修复，对补丁进行分类，再去评估修复工具生成的 补丁的质量是否能被开发人员接受。也是用jml来判断生成的补丁是否过拟合。甚至可以通过补丁的规律来判断在什么情况下会造成复杂度的变化，然后在对这些情况进行综合，形成一个个模板，来提高软件修复工具的突破

   甚至可以用LeetCode上的代码来获取bug程序以及测试用例
